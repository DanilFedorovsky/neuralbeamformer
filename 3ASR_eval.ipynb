{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "from jiwer import wer\n",
    "from transformers.file_utils import cached_path, hf_bucket_url\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "from IPython.lib.display import Audio\n",
    "import torchaudio\n",
    "import torch\n",
    "from pyctcdecode import BeamSearchDecoderCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1, sample_rate = torchaudio.load(\"data1.wav\")\n",
    "data_2, sample_rate = torchaudio.load(\"data2.wav\")\n",
    "output, sample_rate = torchaudio.load(\"output.wav\")\n",
    "\n",
    "path = \"/project/data_asr/CHiME5/data/CHiME5/audio/dev/\"\n",
    "micp5, sample_rate = torchaudio.load(path+\"S02_P05.wav\")\n",
    "micp5 = torch.narrow(micp5, 1, 0, 284929*10)\n",
    "micp6, sample_rate = torchaudio.load(path+\"S02_P06.wav\")\n",
    "micp6 = torch.narrow(micp6, 1, 0, 284929*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 0 unigrams passed as vocabulary. Is this small or artificial data?\n"
     ]
    }
   ],
   "source": [
    "# Get Model\n",
    "model_name = \"nguyenvulebinh/iwslt-asr-wav2vec-large-4500h\"\n",
    "model = SourceFileLoader(\"model\", cached_path(hf_bucket_url(model_name,filename=\"model_handling.py\"))).load_module().Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = processor.feature_extractor(data_1[0], sampling_rate=16000, return_tensors='pt')\n",
    "output_1 = model(**input_1)\n",
    "output_1 = processor.decode(output_1.logits.cpu().detach().numpy()[0], beam_width=100).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = processor.feature_extractor(data_2[0], sampling_rate=16000, return_tensors='pt')\n",
    "output_2 = model(**input_2)\n",
    "output_2 = processor.decode(output_2.logits.cpu().detach().numpy()[0], beam_width=100).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = processor.feature_extractor(output[0], sampling_rate=16000, return_tensors='pt')\n",
    "out = model(**result)\n",
    "out = processor.decode(out.logits.cpu().detach().numpy()[0], beam_width=100).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp5 = processor.feature_extractor(micp5[0], sampling_rate=16000, return_tensors='pt')\n",
    "micp5 = model(**micp5)\n",
    "micp5 = processor.decode(micp5.logits.cpu().detach().numpy()[0], beam_width=100).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp6 = processor.feature_extractor(micp6[0], sampling_rate=16000, return_tensors='pt')\n",
    "micp6 = model(**micp6)\n",
    "micp6 = processor.decode(micp6.logits.cpu().detach().numpy()[0], beam_width=100).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Output into Txt File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[laughs] It's the blue, I think. I think. Okay. [laughs] Let's do lunch. [laughs] Let's do lunch! [laughs] Okay, so here's the pie. Can I help with anything? Wow, that looks good. Um yeah. [noise] Since we Hales, did you put the is the oven heating, or did you put it off cuz it was too hot? Okay. No\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting ground truth for S02\\n\",\n",
    "with open('./S02.json', 'r') as f:\n",
    "    text = json.load(f)\n",
    "    \n",
    "transcript = \"\"\n",
    "for part in text:\n",
    "    transcript += str(part[\"words\"]) + \" \"\n",
    "\n",
    "transcript = transcript[:300]\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P5 Mic WER: 0.9661016949152542\n",
      "P6 Mic WER: 0.847457627118644\n",
      "Array 1 WER: 1.0\n",
      "Array 2 WER: 1.0\n",
      "Beamformer WER: 0.9830508474576272\n"
     ]
    }
   ],
   "source": [
    "print(\"P5 Mic WER:\", wer(transcript,micp5))\n",
    "print(\"P6 Mic WER:\", wer(transcript,micp6))\n",
    "\n",
    "print(\"Array 1 WER:\", wer(transcript,output_1))\n",
    "print(\"Array 2 WER:\", wer(transcript,output_2))\n",
    "print(\"Beamformer WER:\", wer(transcript,out))\n",
    "# ground truth, hypothesis\"\n",
    "\n",
    "#Better performance if short segments (~10s-15s)\n",
    "\n",
    "#1 audio\n",
    "\n",
    "#dataset ICSI Meeting\n",
    "#/dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f158735646e3eab0c4059261eebfec0df7fcce3767322491286d467f4f66baf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
