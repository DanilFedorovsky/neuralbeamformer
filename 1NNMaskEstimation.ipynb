{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: ich mache \"irm_speech, irm_noise = get_irms(stft_clean, stft_noise)\" mit NN\n",
    "# Rest ist wie in https://pytorch.org/audio/0.12.0/tutorials/mvdr_tutorial.html#compute-irms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torchaudio.utils import download_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "SAMPLE_CLEAN = download_asset(\"tutorial-assets/mvdr/clean_speech.wav\")\n",
    "SAMPLE_NOISE = download_asset(\"tutorial-assets/mvdr/noise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def plot_spectrogram(stft, title=\"Spectrogram\", xlim=None):\n",
    "    magnitude = stft.abs()\n",
    "    spectrogram = 20 * torch.log10(magnitude + 1e-8).numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(spectrogram, cmap=\"viridis\", vmin=-100, vmax=0, origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mask(mask, title=\"Mask\", xlim=None):\n",
    "    mask = mask.numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(mask, cmap=\"viridis\", origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def si_snr(estimate, reference, epsilon=1e-8):\n",
    "    estimate = estimate - estimate.mean()\n",
    "    reference = reference - reference.mean()\n",
    "    reference_pow = reference.pow(2).mean(axis=1, keepdim=True)\n",
    "    mix_pow = (estimate * reference).mean(axis=1, keepdim=True)\n",
    "    scale = mix_pow / (reference_pow + epsilon)\n",
    "\n",
    "    reference = scale * reference\n",
    "    error = estimate - reference\n",
    "\n",
    "    reference_pow = reference.pow(2)\n",
    "    error_pow = error.pow(2)\n",
    "\n",
    "    reference_pow = reference_pow.mean(axis=1)\n",
    "    error_pow = error_pow.mean(axis=1)\n",
    "\n",
    "    si_snr = 10 * torch.log10(reference_pow) - 10 * torch.log10(error_pow)\n",
    "    return si_snr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "irm_speech, irm_noise = irm_nn(stft_clean,stft_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the time-invariant PSD matrix given the multi-channel complex-valued STFT coefficients of the mixture speech and the time-frequency mask.\n",
    "\n",
    "psd_transform = torchaudio.transforms.PSD()\n",
    "\n",
    "psd_speech = psd_transform(stft_mix, irm_speech)\n",
    "psd_noise = psd_transform(stft_mix, irm_noise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f158735646e3eab0c4059261eebfec0df7fcce3767322491286d467f4f66baf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
