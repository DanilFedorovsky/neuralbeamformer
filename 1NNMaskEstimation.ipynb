{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Idea: ich mache \"irm_speech, irm_noise = get_irms(stft_clean, stft_noise)\" mit NN\n",
    "# Rest ist wie in https://pytorch.org/audio/0.12.0/tutorials/mvdr_tutorial.html#compute-irms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torchaudio.utils import download_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/pytorch/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/anaconda3/envs/pytorch/lib/python3.8/site-packages (from torchaudio) (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/envs/pytorch/lib/python3.8/site-packages (from torch==1.11.0->torchaudio) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'download_asset' from 'torchaudio.utils.sox_utils' (/Users/danilfedorovsky/miniforge3/envs/ML/lib/python3.10/site-packages/torchaudio/utils/sox_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Code/Beamformer/1NNMaskEstimation.ipynb Zelle 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Beamformer/1NNMaskEstimation.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msox_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m download_asset\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'download_asset' from 'torchaudio.utils.sox_utils' (/Users/danilfedorovsky/miniforge3/envs/ML/lib/python3.10/site-packages/torchaudio/utils/sox_utils.py)"
     ]
    }
   ],
   "source": [
    "from torchaudio.utils.sox_utils import download_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "SAMPLE_CLEAN = download_asset(\"tutorial-assets/mvdr/clean_speech.wav\")\n",
    "SAMPLE_NOISE = download_asset(\"tutorial-assets/mvdr/noise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def plot_spectrogram(stft, title=\"Spectrogram\", xlim=None):\n",
    "    magnitude = stft.abs()\n",
    "    spectrogram = 20 * torch.log10(magnitude + 1e-8).numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(spectrogram, cmap=\"viridis\", vmin=-100, vmax=0, origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mask(mask, title=\"Mask\", xlim=None):\n",
    "    mask = mask.numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(mask, cmap=\"viridis\", origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def si_snr(estimate, reference, epsilon=1e-8):\n",
    "    estimate = estimate - estimate.mean()\n",
    "    reference = reference - reference.mean()\n",
    "    reference_pow = reference.pow(2).mean(axis=1, keepdim=True)\n",
    "    mix_pow = (estimate * reference).mean(axis=1, keepdim=True)\n",
    "    scale = mix_pow / (reference_pow + epsilon)\n",
    "\n",
    "    reference = scale * reference\n",
    "    error = estimate - reference\n",
    "\n",
    "    reference_pow = reference.pow(2)\n",
    "    error_pow = error.pow(2)\n",
    "\n",
    "    reference_pow = reference_pow.mean(axis=1)\n",
    "    error_pow = error_pow.mean(axis=1)\n",
    "\n",
    "    si_snr = 10 * torch.log10(reference_pow) - 10 * torch.log10(error_pow)\n",
    "    return si_snr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio\n",
    "waveform_clean, sr = torchaudio.load(SAMPLE_CLEAN)\n",
    "waveform_noise, sr2 = torchaudio.load(SAMPLE_NOISE)\n",
    "assert sr == sr2 == SAMPLE_RATE\n",
    "# The mixture waveform is a combination of clean and noise waveforms\n",
    "waveform_mix = waveform_clean + waveform_noise\n",
    "\n",
    "# Improve Robustness with double precision floating points\n",
    "waveform_mix = waveform_mix.to(torch.double)\n",
    "waveform_clean = waveform_clean.to(torch.double)\n",
    "waveform_noise = waveform_noise.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute STFT\n",
    "N_FFT = 1024\n",
    "N_HOP = 256\n",
    "stft = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=N_HOP,\n",
    "    power=None,\n",
    ")\n",
    "istft = torchaudio.transforms.InverseSpectrogram(n_fft=N_FFT, hop_length=N_HOP)\n",
    "\n",
    "stft_mix = stft(waveform_mix)\n",
    "stft_clean = stft(waveform_clean)\n",
    "stft_noise = stft(waveform_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(stft_mix[0], \"Spectrogram of Mixture Speech (dB)\")\n",
    "Audio(waveform_mix[0], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(stft_noise[0], \"Spectrogram of Noise (dB)\")\n",
    "Audio(waveform_noise[0], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "irm_speech, irm_noise = irm_nn(stft_clean,stft_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Masks\n",
    "def get_irms(stft_clean, stft_noise):\n",
    "    mag_clean = stft_clean.abs() ** 2\n",
    "    mag_noise = stft_noise.abs() ** 2\n",
    "    irm_speech = mag_clean / (mag_clean + mag_noise)\n",
    "    irm_noise = mag_noise / (mag_clean + mag_noise)\n",
    "    return irm_speech[REFERENCE_CHANNEL], irm_noise[REFERENCE_CHANNEL]\n",
    "\n",
    "irm_speech, irm_noise = get_irms(stft_clean, stft_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(irm_speech, \"IRM of the Target Speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(irm_noise, \"IRM of the Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the time-invariant PSD matrix given the multi-channel complex-valued STFT coefficients of the mixture speech and the time-frequency mask.\n",
    "\n",
    "psd_transform = torchaudio.transforms.PSD()\n",
    "\n",
    "psd_speech = psd_transform(stft_mix, irm_speech)\n",
    "psd_noise = psd_transform(stft_mix, irm_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BF\n",
    "mvdr_transform = torchaudio.transforms.SoudenMVDR()\n",
    "stft_souden = mvdr_transform(stft_mix, psd_speech, psd_noise, reference_channel=REFERENCE_CHANNEL)\n",
    "waveform_souden = istft(stft_souden, length=waveform_mix.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(stft_souden, \"Enhanced Spectrogram by SoudenMVDR (dB)\")\n",
    "waveform_souden = waveform_souden.reshape(1, -1)\n",
    "print(f\"Si-SNR score: {si_snr(waveform_souden, waveform_clean[0:1])}\")\n",
    "Audio(waveform_souden, rate=SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5b916051ec391ef3c1c0123575e59cad2c35863d294dd079abc5845c0e5babb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
