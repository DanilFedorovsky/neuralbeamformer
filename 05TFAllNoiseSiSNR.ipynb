{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dfedorovsky/anaconda3/envs/beamformer/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Module, Linear, Sigmoid, LSTM, BCELoss, Conv2d, MaxPool2d, LayerNorm, MultiheadAttention, Dropout\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from pytorch_model_summary import summary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from torchmetrics import ScaleInvariantSignalNoiseRatio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoaderAll\n",
    "\n",
    "X,Y_mask,speech,mix1,X_complex = DataLoaderAll.data_loader(n_noise=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskNet + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------\n",
      "           Layer (type)                   Output Shape         Param #     Tr. Param #\n",
      "=======================================================================================\n",
      "   PositionalEncoding-1                  [4, 513, 196]               0               0\n",
      "            LayerNorm-2                  [4, 513, 196]             392             392\n",
      "   MultiheadAttention-3     [4, 513, 196], [513, 4, 4]         154,448         154,448\n",
      "            LayerNorm-4                  [4, 513, 196]             392             392\n",
      "               Linear-5                 [4, 513, 1024]         201,728         201,728\n",
      "               Linear-6                  [4, 513, 196]         200,900         200,900\n",
      "            LayerNorm-7                  [4, 513, 196]             392             392\n",
      "   MultiheadAttention-8     [4, 513, 196], [513, 4, 4]         154,448         154,448\n",
      "            LayerNorm-9                  [4, 513, 196]             392             392\n",
      "              Linear-10                 [4, 513, 1024]         201,728         201,728\n",
      "              Linear-11                  [4, 513, 196]         200,900         200,900\n",
      "              Linear-12                  [513, 196, 1]               5               5\n",
      "             Sigmoid-13                  [513, 196, 1]               0               0\n",
      "=======================================================================================\n",
      "Total params: 1,115,725\n",
      "Trainable params: 1,115,725\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MASK NET\n",
    "SAMPLE_RATE = 16000\n",
    "INPUT_CHANNEL = 4 # Always two -> Real and Imaginary part \n",
    "D_TF = 1024#1024\n",
    "\n",
    "class MaskNet(Module):\n",
    "    def __init__(self,noise=False):\n",
    "        super(MaskNet, self).__init__()\n",
    "\n",
    "        self.pe = PositionalEncoding(d_model=196)\n",
    "        self.ln11 = LayerNorm(normalized_shape=(196))\n",
    "        self.ln12 = LayerNorm(normalized_shape=(196))\n",
    "        self.mha1 = MultiheadAttention(embed_dim=196,num_heads=14,dropout=0.1)\n",
    "        self.lintf1 = Linear(in_features=196,out_features=D_TF)#1024 instead of 256!\n",
    "        self.lintf12 = Linear(in_features=D_TF,out_features=196)\n",
    "\n",
    "        self.pe2 = PositionalEncoding(d_model=196)\n",
    "        self.ln21 = LayerNorm(normalized_shape=(196))\n",
    "        self.ln22 = LayerNorm(normalized_shape=(196))\n",
    "        self.mha2 = MultiheadAttention(embed_dim=196,num_heads=14,dropout=0.1)\n",
    "        self.lintf2 = Linear(in_features=196,out_features=D_TF)#1024 instead of 256!\n",
    "        self.lintf22 = Linear(in_features=D_TF,out_features=196)\n",
    "\n",
    "        self.fc = Linear(in_features=4,out_features=1)\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = x.reshape(INPUT_CHANNEL,513,196)\n",
    "\n",
    "        # Transformer 1\n",
    "        y = self.pe(x)\n",
    "        z = self.ln11(y)\n",
    "        z, _ = self.mha1(z,z,z)\n",
    "        z_2 = z+y\n",
    "        z = self.ln12(z_2)\n",
    "        z = self.lintf1(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.lintf12(z)\n",
    "        x = z+z_2+x\n",
    "\n",
    "        # Transformer 2\n",
    "        y = self.pe(x)\n",
    "        z = self.ln21(y)\n",
    "        z, _ = self.mha2(z,z,z)\n",
    "        z_2 = z+y\n",
    "        z = self.ln22(z_2)\n",
    "        z = self.lintf2(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.lintf22(z)\n",
    "        x = z+z_2+x\n",
    "        \n",
    "        x = x.view(513,196,4)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        speech_pred = self.sigmoid(x)\n",
    "        return speech_pred.reshape(513,-1)#, noise_pred\n",
    "\n",
    "print(summary(MaskNet(),torch.zeros((513, 196, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dfedorovsky/anaconda3/envs/beamformer/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (ScaleInvariantSignalNoiseRatio). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n",
      "Epoch: 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 1 : 0.7857393610384316\n",
      "Total Validation Loss in Epoch 1 : 2.2718957126140595\n",
      "0\n",
      "Epoch: 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 2 : 1.2698482548703904\n",
      "Total Validation Loss in Epoch 2 : 2.8402023017406464\n",
      "0\n",
      "Epoch: 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 3 : 1.7675975931310095\n",
      "Total Validation Loss in Epoch 3 : 1.6163235768675803\n",
      "0\n",
      "Epoch: 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 4 : 2.4629184586515183\n",
      "Total Validation Loss in Epoch 4 : 3.155985748767853\n",
      "0\n",
      "Epoch: 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 5 : 2.879149901188126\n",
      "Total Validation Loss in Epoch 5 : 1.9242789149284363\n",
      "0\n",
      "Epoch: 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 6 : 3.316169837573063\n",
      "Total Validation Loss in Epoch 6 : 3.4161229610443113\n",
      "0\n",
      "Epoch: 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 7 : 3.731171283540898\n",
      "Total Validation Loss in Epoch 7 : 5.048330867290497\n",
      "0\n",
      "Epoch: 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 8 : 3.921861916114576\n",
      "Total Validation Loss in Epoch 8 : 2.3924390077590942\n",
      "0\n",
      "Epoch: 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 9 : 3.584159147015307\n",
      "Total Validation Loss in Epoch 9 : 7.099445915222168\n",
      "0\n",
      "Epoch: 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 10 : 4.019801840008702\n",
      "Total Validation Loss in Epoch 10 : 3.302844685316086\n",
      "0\n",
      "Epoch: 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 11 : 4.520712224135932\n",
      "Total Validation Loss in Epoch 11 : 8.601692988350987\n",
      "0\n",
      "Epoch: 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 12 : 4.260668016878888\n",
      "Total Validation Loss in Epoch 12 : 1.5375338315963745\n",
      "0\n",
      "Epoch: 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 13 : 4.553042861701921\n",
      "Total Validation Loss in Epoch 13 : 3.0002325773239136\n",
      "0\n",
      "Epoch: 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 62.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 14 : 4.8375725620316805\n",
      "Total Validation Loss in Epoch 14 : 7.401397180557251\n",
      "0\n",
      "Epoch: 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 15 : 5.166690212825779\n",
      "Total Validation Loss in Epoch 15 : 2.1895316362380983\n",
      "0\n",
      "Epoch: 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 16 : 4.4645830528475345\n",
      "Total Validation Loss in Epoch 16 : 4.041794141754508\n",
      "0\n",
      "Epoch: 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 17 : 5.04523831537785\n",
      "Total Validation Loss in Epoch 17 : 6.270254448056221\n",
      "0\n",
      "Epoch: 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 18 : 5.281455823520664\n",
      "Total Validation Loss in Epoch 18 : 3.8326195307075976\n",
      "0\n",
      "Epoch: 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 19 : 5.419602782357484\n",
      "Total Validation Loss in Epoch 19 : 5.865248066186905\n",
      "0\n",
      "Epoch: 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 62.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 20 : 5.638963273984147\n",
      "Total Validation Loss in Epoch 20 : 7.799265837669372\n",
      "0\n",
      "Epoch: 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 21 : 4.864383471017703\n",
      "Total Validation Loss in Epoch 21 : 6.02901109457016\n",
      "0\n",
      "Epoch: 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 22 : 4.946181467339862\n",
      "Total Validation Loss in Epoch 22 : 4.569690153002739\n",
      "0\n",
      "Epoch: 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 23 : 4.5965787269352\n",
      "Total Validation Loss in Epoch 23 : 7.82450088262558\n",
      "0\n",
      "Epoch: 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 24 : 5.233775342490058\n",
      "Total Validation Loss in Epoch 24 : 6.85005476474762\n",
      "0\n",
      "Epoch: 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 25 : 4.963838529791243\n",
      "Total Validation Loss in Epoch 25 : 7.216120100021362\n",
      "0\n",
      "Epoch: 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 26 : 5.58498846583115\n",
      "Total Validation Loss in Epoch 26 : 8.691330063343049\n",
      "0\n",
      "Epoch: 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 58.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 27 : 5.499956252883188\n",
      "Total Validation Loss in Epoch 27 : 1.6978962123394012\n",
      "0\n",
      "Epoch: 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 28 : 5.588547539929859\n",
      "Total Validation Loss in Epoch 28 : 7.342556452751159\n",
      "0\n",
      "Epoch: 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 29 : 5.613226922495058\n",
      "Total Validation Loss in Epoch 29 : 3.97103950381279\n",
      "0\n",
      "Epoch: 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 30 : 5.26797355970554\n",
      "Total Validation Loss in Epoch 30 : 9.141066801548003\n",
      "0\n",
      "Epoch: 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 31 : 6.1278490524897355\n",
      "Total Validation Loss in Epoch 31 : 5.8385877221822735\n",
      "0\n",
      "Epoch: 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 32 : 5.900671539265662\n",
      "Total Validation Loss in Epoch 32 : 7.5262951254844666\n",
      "0\n",
      "Epoch: 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 33 : 5.876399207795039\n",
      "Total Validation Loss in Epoch 33 : 6.867916989326477\n",
      "0\n",
      "Epoch: 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 34 : 6.483943164504598\n",
      "Total Validation Loss in Epoch 34 : 7.329887044429779\n",
      "0\n",
      "Epoch: 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 35 : 6.6128747147601095\n",
      "Total Validation Loss in Epoch 35 : 8.622773122787475\n",
      "0\n",
      "Epoch: 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 36 : 6.45481454147771\n",
      "Total Validation Loss in Epoch 36 : 5.9568421125411986\n",
      "0\n",
      "Epoch: 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 37 : 6.634877652476542\n",
      "Total Validation Loss in Epoch 37 : 8.761619997024535\n",
      "0\n",
      "Epoch: 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 38 : 6.7681396298911425\n",
      "Total Validation Loss in Epoch 38 : 2.5962726712226867\n",
      "0\n",
      "Epoch: 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 39 : 4.852250651242677\n",
      "Total Validation Loss in Epoch 39 : 4.96010788679123\n",
      "0\n",
      "Epoch: 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 40 : 6.751804574100941\n",
      "Total Validation Loss in Epoch 40 : 5.479342037439347\n",
      "0\n",
      "Epoch: 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 41 : 7.09492656403291\n",
      "Total Validation Loss in Epoch 41 : 6.524583441019058\n",
      "0\n",
      "Epoch: 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 42 : 7.403355442085769\n",
      "Total Validation Loss in Epoch 42 : 6.970249590277672\n",
      "0\n",
      "Epoch: 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 43 : 7.416719612840563\n",
      "Total Validation Loss in Epoch 43 : 11.613452672958374\n",
      "0\n",
      "Epoch: 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 44 : 7.327500909350812\n",
      "Total Validation Loss in Epoch 44 : 8.810090732574462\n",
      "0\n",
      "Epoch: 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 45 : 7.7085768622923645\n",
      "Total Validation Loss in Epoch 45 : 7.473319959640503\n",
      "0\n",
      "Epoch: 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 46 : 7.843254071510397\n",
      "Total Validation Loss in Epoch 46 : 8.171651530265809\n",
      "0\n",
      "Epoch: 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 62.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 47 : 7.623603357739746\n",
      "Total Validation Loss in Epoch 47 : 7.706465005874634\n",
      "0\n",
      "Epoch: 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 48 : 8.123023582478403\n",
      "Total Validation Loss in Epoch 48 : 2.9144257068634034\n",
      "0\n",
      "Epoch: 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 49 : 8.072199265622244\n",
      "Total Validation Loss in Epoch 49 : 8.02601710446179\n",
      "0\n",
      "Epoch: 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 50 : 7.966369083836675\n",
      "Total Validation Loss in Epoch 50 : 9.73108685016632\n",
      "0\n",
      "Epoch: 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 51 : 8.002666833798866\n",
      "Total Validation Loss in Epoch 51 : 6.406892454624176\n",
      "0\n",
      "Epoch: 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 52 : 8.29615359986294\n",
      "Total Validation Loss in Epoch 52 : 6.01984429359436\n",
      "0\n",
      "Epoch: 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 53 : 8.297331054023699\n",
      "Total Validation Loss in Epoch 53 : 4.253023497015238\n",
      "0\n",
      "Epoch: 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 54 : 8.564087026866385\n",
      "Total Validation Loss in Epoch 54 : 9.418537187576295\n",
      "0\n",
      "Epoch: 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 55 : 8.509645566904451\n",
      "Total Validation Loss in Epoch 55 : 10.149158501625061\n",
      "0\n",
      "Epoch: 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 56 : 7.77486483372678\n",
      "Total Validation Loss in Epoch 56 : 9.713460636138915\n",
      "0\n",
      "Epoch: 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 57 : 8.770600651097949\n",
      "Total Validation Loss in Epoch 57 : 7.438054101914167\n",
      "0\n",
      "Epoch: 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 58 : 8.782534685526626\n",
      "Total Validation Loss in Epoch 58 : 2.20897262096405\n",
      "0\n",
      "Epoch: 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 59 : 8.895739065165632\n",
      "Total Validation Loss in Epoch 59 : 8.512424659729003\n",
      "0\n",
      "Epoch: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 60 : 8.417302981678397\n",
      "Total Validation Loss in Epoch 60 : 9.86786048412323\n",
      "0\n",
      "Epoch: 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 61 : 9.05540094393026\n",
      "Total Validation Loss in Epoch 61 : 8.387591099739074\n",
      "0\n",
      "Epoch: 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 62 : 8.987282806946197\n",
      "Total Validation Loss in Epoch 62 : 10.731864881515502\n",
      "0\n",
      "Epoch: 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 63 : 9.088860212428495\n",
      "Total Validation Loss in Epoch 63 : 11.142126178741455\n",
      "0\n",
      "Epoch: 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 64 : 9.24137814443698\n",
      "Total Validation Loss in Epoch 64 : 5.064655733108521\n",
      "0\n",
      "Epoch: 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 65 : 9.223741422269493\n",
      "Total Validation Loss in Epoch 65 : 8.865287637710571\n",
      "0\n",
      "Epoch: 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 66 : 9.194622917592175\n",
      "Total Validation Loss in Epoch 66 : 7.246748518943787\n",
      "0\n",
      "Epoch: 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 67 : 8.74885898310307\n",
      "Total Validation Loss in Epoch 67 : 10.028776550292969\n",
      "0\n",
      "Epoch: 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 68 : 9.374361484187656\n",
      "Total Validation Loss in Epoch 68 : 7.9412676900625225\n",
      "0\n",
      "Epoch: 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 60.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 69 : 9.437175833660062\n",
      "Total Validation Loss in Epoch 69 : 4.086843720078468\n",
      "0\n",
      "Epoch: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 70 : 9.540161636006554\n",
      "Total Validation Loss in Epoch 70 : 11.1863232254982\n",
      "0\n",
      "Epoch: 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 71 : 9.628034411173779\n",
      "Total Validation Loss in Epoch 71 : 10.828449261188506\n",
      "0\n",
      "Epoch: 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 72 : 9.636409466068843\n",
      "Total Validation Loss in Epoch 72 : 6.272598078846931\n",
      "0\n",
      "Epoch: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 73 : 9.561621338424505\n",
      "Total Validation Loss in Epoch 73 : 7.666555762290955\n",
      "0\n",
      "Epoch: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 74 : 9.744335229266087\n",
      "Total Validation Loss in Epoch 74 : 12.841111755371093\n",
      "0\n",
      "Epoch: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 75 : 9.798182440007105\n",
      "Total Validation Loss in Epoch 75 : 8.504199063777923\n",
      "0\n",
      "Epoch: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 76 : 9.79902790401876\n",
      "Total Validation Loss in Epoch 76 : 6.883256733417511\n",
      "0\n",
      "Epoch: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 77 : 9.953873188452794\n",
      "Total Validation Loss in Epoch 77 : 5.786066055297852\n",
      "0\n",
      "Epoch: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 78 : 9.95742519622267\n",
      "Total Validation Loss in Epoch 78 : 12.841485071182252\n",
      "0\n",
      "Epoch: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 79 : 9.850604360300116\n",
      "Total Validation Loss in Epoch 79 : 11.095275402069092\n",
      "0\n",
      "Epoch: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 80 : 9.751919285435113\n",
      "Total Validation Loss in Epoch 80 : 7.920574712753296\n",
      "0\n",
      "Epoch: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 81 : 9.958828382123727\n",
      "Total Validation Loss in Epoch 81 : 9.344005134701728\n",
      "0\n",
      "Epoch: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 82 : 9.908571027934551\n",
      "Total Validation Loss in Epoch 82 : 9.375715494155884\n",
      "0\n",
      "Epoch: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:36<00:00, 54.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 83 : 7.365263970257715\n",
      "Total Validation Loss in Epoch 83 : 6.267049714922905\n",
      "0\n",
      "Epoch: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 84 : 9.826225014471216\n",
      "Total Validation Loss in Epoch 84 : 9.002984917163849\n",
      "0\n",
      "Epoch: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 58.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 85 : 10.094812024866231\n",
      "Total Validation Loss in Epoch 85 : 11.826831579208374\n",
      "0\n",
      "Epoch: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 86 : 10.163161582184955\n",
      "Total Validation Loss in Epoch 86 : 8.313956171274185\n",
      "0\n",
      "Epoch: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 87 : 10.235999675666914\n",
      "Total Validation Loss in Epoch 87 : 9.465381354093552\n",
      "0\n",
      "Epoch: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 88 : 10.023714277800172\n",
      "Total Validation Loss in Epoch 88 : 9.402114614844322\n",
      "0\n",
      "Epoch: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 89 : 9.97057563954452\n",
      "Total Validation Loss in Epoch 89 : 8.591421711444855\n",
      "0\n",
      "Epoch: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 90 : 9.919413410372567\n",
      "Total Validation Loss in Epoch 90 : 8.260297882556916\n",
      "0\n",
      "Epoch: 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 91 : 10.343913943231687\n",
      "Total Validation Loss in Epoch 91 : 11.411947631835938\n",
      "0\n",
      "Epoch: 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 58.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 92 : 10.35877291629091\n",
      "Total Validation Loss in Epoch 92 : 8.028985786437989\n",
      "0\n",
      "Epoch: 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 93 : 10.488188889351674\n",
      "Total Validation Loss in Epoch 93 : 15.349675559997559\n",
      "0\n",
      "Epoch: 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 62.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 94 : 10.35149494141247\n",
      "Total Validation Loss in Epoch 94 : 11.44174349308014\n",
      "0\n",
      "Epoch: 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 95 : 10.468838385533308\n",
      "Total Validation Loss in Epoch 95 : 13.529879283905029\n",
      "0\n",
      "Epoch: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 96 : 10.412978927241639\n",
      "Total Validation Loss in Epoch 96 : 8.574351716041566\n",
      "0\n",
      "Epoch: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:35<00:00, 56.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 97 : 10.282279933549464\n",
      "Total Validation Loss in Epoch 97 : 11.600073647499084\n",
      "0\n",
      "Epoch: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 98 : 10.512391176309437\n",
      "Total Validation Loss in Epoch 98 : 11.744762396812439\n",
      "0\n",
      "Epoch: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 99 : 10.43679190613469\n",
      "Total Validation Loss in Epoch 99 : 8.669315940141678\n",
      "0\n",
      "Epoch: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:34<00:00, 57.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss in Epoch 100 : 10.611896385782165\n",
      "Total Validation Loss in Epoch 100 : 6.594376587867737\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "LEN_TRAIN = 2000\n",
    "NUM_CHANNEL = 2 # Number of Mic Inputs (>=2 for BF)\n",
    "REFERENCE_CHANNEL = 0\n",
    "INIT_LR = 0.0001#0.0001\n",
    "BATCH_SIZE = 1#64\n",
    "LEARN_LOSS_PARAMS = False\n",
    "device =  torch.device('cuda:3') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = MaskNet().to(device)\n",
    "model= torch.nn.DataParallel(model,device_ids=[3])\n",
    "\n",
    "#lossBCE = BCELoss()\n",
    "lossSiSNR = ScaleInvariantSignalNoiseRatio().to(device)\n",
    "\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lambda1 = lambda epoch: 0.65 ** epoch\n",
    "#lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=opt, lr_lambda=lambda1)\n",
    "\n",
    "H = {\n",
    "    \"train_loss\":[],\n",
    "    \"train_acc\":[],\n",
    "    \"val_loss\":[],\n",
    "    \"val_acc\":[]\n",
    "}\n",
    "\n",
    "def check_accuracy_validation(model):\n",
    "    example_nr = int(np.random.random()*(len(X)-LEN_TRAIN)+LEN_TRAIN)\n",
    "    model.eval()\n",
    "    pred = maskToWave(model(X[example_nr]),example_nr)\n",
    "    val_loss = lossSiSNR(pred,Y[example_nr][0])\n",
    "    model.train()\n",
    "    return val_loss\n",
    "\n",
    "istft = torchaudio.transforms.InverseSpectrogram(n_fft=1024, hop_length=256).to(device)\n",
    "def maskToWave(speech_pred,i):\n",
    "        #speech_pred = (speech_pred>0.2).float()\n",
    "        noise_pred = torch.ones([513,speech_pred.shape[1]]).to(device)-speech_pred\n",
    "        psd_transform = torchaudio.transforms.PSD()\n",
    "        psd_speech = psd_transform(X_complex[i], speech_pred)\n",
    "        psd_noise = psd_transform(X_complex[i], noise_pred)\n",
    "        mvdr_transform = torchaudio.transforms.SoudenMVDR()\n",
    "        stft_souden = mvdr_transform(X_complex[i], psd_speech, psd_noise, reference_channel=0)\n",
    "        waveform_souden = istft(stft_souden, length=len(speech[i][0]))#X[i].shape[-1])\n",
    "        return waveform_souden.reshape(-1)\n",
    "\n",
    "\n",
    "print(\"[INFO] training the network...\")\n",
    "#X = stft_mix[:50].to(device)\n",
    "#Y = Y.to(device)\n",
    "X = X.to(device)\n",
    "Y = speech.to(device)\n",
    "X_complex = X_complex.to(device)\n",
    "trainX = X[:LEN_TRAIN]\n",
    "trainY = Y\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    print(\"Epoch:\",str(epoch+1)+\"/\"+str(EPOCHS))\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "\n",
    "    for i in tqdm(range(0,len(trainX))): # Iterate over Training Examples\n",
    "        y_s = trainY[i][0] # 0 speech only\n",
    "        x = trainX[i]\n",
    "        try:\n",
    "            speech_pred=maskToWave(model(x),i)\n",
    "        except Exception:\n",
    "            continue\n",
    "        try:\n",
    "            loss = -lossSiSNR(speech_pred,y_s)\n",
    "            # zero out the gradients, perform the backpropagation step, and update the weights\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            H[\"train_loss\"].append(float(loss))\n",
    "        except Exception:\n",
    "            continue\n",
    "        if i % 10 == 0:\n",
    "            val_loss = check_accuracy_validation(model)\n",
    "            #H[\"val_acc\"].append(val_acc)\n",
    "            H[\"val_loss\"].append(float(val_loss))\n",
    "    # Print results of Epoch        \n",
    "    #print(\"Average Training Accuracy in Epoch\",str(epoch+1),\":\",np.mean(np.array(H[\"train_acc\"])))\n",
    "    print(\"Average Training Loss in Epoch\",str(epoch+1),\":\",(-sum(H[\"train_loss\"][-2000:]))/2000)\n",
    "    #print(\"Average Validation Accuracy in Epoch\",str(epoch+1),\":\",np.mean(np.array(H[\"val_acc\"])))\n",
    "    print(\"Total Validation Loss in Epoch\",str(epoch+1),\":\",(sum(H[\"val_loss\"][-10:]))/10)\n",
    "    # Save Model after Epoch        \n",
    "    MODEL_SAVE_PATH = '/project/data_asr/CHiME5/data/librenoise/models/TFall'\n",
    "    if (epoch+1)%10 == 0:\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH + \"epoch\" + str(epoch+1) + \".pt\")\n",
    "    print(totalTrainLoss)\n",
    "PICKLE_SAVE_PATH = '/project/data_asr/CHiME5/data/librenoise/models/params.pkl'\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH + \"final\" + \".pt\")\n",
    "with open(PICKLE_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(H, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskNet(\n",
       "  (pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln11): LayerNorm((196,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln12): LayerNorm((196,), eps=1e-05, elementwise_affine=True)\n",
       "  (mha1): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=196, out_features=196, bias=True)\n",
       "  )\n",
       "  (lintf1): Linear(in_features=196, out_features=1024, bias=True)\n",
       "  (lintf12): Linear(in_features=1024, out_features=196, bias=True)\n",
       "  (pe2): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln21): LayerNorm((196,), eps=1e-05, elementwise_affine=True)\n",
       "  (ln22): LayerNorm((196,), eps=1e-05, elementwise_affine=True)\n",
       "  (mha2): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=196, out_features=196, bias=True)\n",
       "  )\n",
       "  (lintf2): Linear(in_features=196, out_features=1024, bias=True)\n",
       "  (lintf22): Linear(in_features=1024, out_features=196, bias=True)\n",
       "  (fc): Linear(in_features=4, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = MODEL_SAVE_PATH = \"/project/data_asr/CHiME5/data/librenoise/models/TFallepoch100.pt\"\n",
    "#device = torch.device('cuda:0')\n",
    "state_dict = torch.load(PATH)\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.` from state dict\n",
    "    new_state_dict[name] = v\n",
    "# load params\n",
    "model = MaskNet()\n",
    "model.load_state_dict(new_state_dict)\n",
    "#model= torch.nn.DataParallel(model)\n",
    "#model.load_state_dict(torch.load(PATH))#,map_location=device))\n",
    "#model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.cpu()\n",
    "Y = Y_mask.cpu()\n",
    "def evaluate_example(e_nr):\n",
    "    model.eval()\n",
    "    speech_pred = (model(X[e_nr])>0.15).float()\n",
    "    noise_pred = torch.ones([513,X[e_nr].shape[1]])-speech_pred\n",
    "    plot_mask(speech_pred, title=\"Prediction Speech\")\n",
    "    plot_mask(noise_pred, title=\"Prediction Noise\")\n",
    "    plot_mask(Y_mask[e_nr][0], title=\"Reference Speech\")\n",
    "    plot_mask(Y_mask[e_nr][1], title=\"Reference Noise\")\n",
    "\n",
    "def plot_mask(mask, title=\"Mask\", xlim=None):\n",
    "    mask = mask.detach().numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(mask, cmap=\"viridis\", origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()\n",
    "\n",
    "evaluate_example(2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000])\n",
      "tensor([0.0259, 0.0265, 0.0251,  ..., 0.0399, 0.0367, 0.0335])\n",
      "Si-SNR score: 6.385181427001953\n"
     ]
    }
   ],
   "source": [
    "istft = torchaudio.transforms.InverseSpectrogram(n_fft=1024, hop_length=256)\n",
    "X_complex = X_complex.cpu()\n",
    "\n",
    "def si_snr(estimate, reference, epsilon=1e-8):\n",
    "    estimate = estimate - estimate.mean()\n",
    "    reference = reference - reference.mean()\n",
    "    reference_pow = reference.pow(2).mean(axis=1, keepdim=True)\n",
    "    mix_pow = (estimate * reference).mean(axis=1, keepdim=True)\n",
    "    scale = mix_pow / (reference_pow + epsilon)\n",
    "\n",
    "    reference = scale * reference\n",
    "    error = estimate - reference\n",
    "\n",
    "    reference_pow = reference.pow(2)\n",
    "    error_pow = error.pow(2)\n",
    "\n",
    "    reference_pow = reference_pow.mean(axis=1)\n",
    "    error_pow = error_pow.mean(axis=1)\n",
    "\n",
    "    si_snr = 10 * torch.log10(reference_pow) - 10 * torch.log10(error_pow)\n",
    "    return si_snr.item()\n",
    "\n",
    "def evaluateSiSNR(wave, i):\n",
    "    score = si_snr(wave, speech[i])\n",
    "    #print(f\"Si-SNR score: {score}\") \n",
    "    return score\n",
    "\n",
    "def maskToWave(speech_pred,noise_pred,mix,i):\n",
    "        model.eval()\n",
    "        psd_transform = torchaudio.transforms.PSD()\n",
    "        psd_speech = psd_transform(mix[i], speech_pred)\n",
    "        psd_noise = psd_transform(mix[i], noise_pred)\n",
    "        mvdr_transform = torchaudio.transforms.SoudenMVDR()\n",
    "        stft_souden = mvdr_transform(mix[i], psd_speech, psd_noise, reference_channel=0)\n",
    "        waveform_souden = istft(stft_souden, length=len(speech[i][0]))#X[i].shape[-1])\n",
    "        return waveform_souden.reshape(-1)\n",
    "\n",
    "def maskToWave(speech_pred,i):\n",
    "        #speech_pred = (speech_pred>0.2).float()\n",
    "        noise_pred = torch.ones([513,speech_pred.shape[1]])-speech_pred\n",
    "        psd_transform = torchaudio.transforms.PSD()\n",
    "        psd_speech = psd_transform(X_complex[i], speech_pred)\n",
    "        psd_noise = psd_transform(X_complex[i], noise_pred)\n",
    "        mvdr_transform = torchaudio.transforms.SoudenMVDR()\n",
    "        stft_souden = mvdr_transform(X_complex[i], psd_speech, psd_noise, reference_channel=0)\n",
    "        waveform_souden = istft(stft_souden, length=len(speech[i][0]))#X[i].shape[-1])\n",
    "        return waveform_souden.reshape(-1)\n",
    "\n",
    "def save_sample(i,wave,sample_rate=SAMPLE_RATE):\n",
    "    torchaudio.save(\"./outputs/sample_reference.wav\", speech[i].reshape(1,-1),sample_rate)\n",
    "    torchaudio.save(\"./outputs/sample_input.wav\", mix1[i].reshape(1,-1),sample_rate)\n",
    "    torchaudio.save(\"./outputs/model_out.wav\",wave.reshape(1,-1),16000)\n",
    "\n",
    "index = 2013\n",
    "speech_pred = (model(X[index])>0.2).float()\n",
    "#noise_pred = torch.ones([513,speech_pred.shape[1]])-speech_pred\n",
    "wave = maskToWave(speech_pred,index)#noise_pred,X_complex,index)#X hat nicht mehr nur 2, sondern 4 channel\n",
    "print(wave.shape)\n",
    "print(wave)\n",
    "save_sample(index, wave=wave)\n",
    "score = evaluateSiSNR(wave,index)#Should be ~28\n",
    "print(f\"Si-SNR score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.386744122077866"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set\n",
    "scores = []\n",
    "for index in range(2000,2703):\n",
    "    speech_pred = (model(X[index])>0.2).float()\n",
    "    wave = maskToWave(speech_pred,index)#X hat nicht mehr nur 2, sondern 4 channel\n",
    "    scores.append(si_snr(wave, speech[index])-si_snr(mix1[index],speech[index]))\n",
    "\n",
    "np.mean(scores)\n",
    "\n",
    "# Average improvement with 100 noises: 3.3867 (100 epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('beamformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7edcfa7c72349f2a40b8bb9d00f805dd689758e4b70f704e502841c884b714f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
