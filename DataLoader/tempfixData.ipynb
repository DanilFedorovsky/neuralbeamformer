{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADER\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "import random\n",
    "\n",
    "y_mask=True\n",
    "n_noise = -1\n",
    "REFERENCE_CHANNEL = 0\n",
    "SAME_LENGTH = True\n",
    "THR_S = 0.5 # Threshold for speech IRM\n",
    "THR_N = 0.5\n",
    "N_PATH = \"/project/data_asr/CHiME5/data/librenoise/free-sound/\"#\"/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Data/noise/free-sound/\"\n",
    "S_PATH = \"/project/data_asr/CHiME5/data/librenoise/dev/dev-clean/\"#\"/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Data/LibriSpeech/dev-clean/\"\n",
    "MODEL_SAVE_PATH = \"/project/data_asr/CHiME5/data/librenoise/models/\"\n",
    "def load_noise(N_PATH=N_PATH):\n",
    "    noise = []\n",
    "    for file in  os.listdir(N_PATH):\n",
    "        if file[-4:] == \".wav\":\n",
    "            sound, _ = torchaudio.load(N_PATH+file)\n",
    "            noise.append(sound)\n",
    "    return noise\n",
    "\n",
    "\n",
    "def load_speech(S_PATH=S_PATH):\n",
    "    speech = []\n",
    "    for folder in  os.listdir(S_PATH):\n",
    "        if os.path.isdir(S_PATH+folder):\n",
    "            for subfolder in os.listdir(S_PATH+folder):\n",
    "                if os.path.isdir(S_PATH+folder+\"/\"+subfolder):\n",
    "                    for file in os.listdir(S_PATH+folder+\"/\"+subfolder):\n",
    "                        if file[-5:] == \".flac\":\n",
    "                            sound, _ = torchaudio.load(S_PATH+folder+\"/\"+subfolder+\"/\"+file)\n",
    "                            if SAME_LENGTH:\n",
    "                                try:\n",
    "                                    sound = torch.narrow(sound,1,0,50000)# Narrow to 50000\n",
    "                                except Exception:\n",
    "                                    # add zeros to make sound 50000 long\n",
    "                                    len_sound = sound.shape[1]\n",
    "                                    add_zeros = 50000 - len_sound\n",
    "                                    add_zeros = torch.zeros(add_zeros).reshape(1,-1)\n",
    "                                    sound = torch.concat([sound,add_zeros],dim=1)\n",
    "                            speech.append(sound)\n",
    "    return speech\n",
    "\n",
    "def add_noise_to_speech(speech, noise, ratio1: float, ratio2: float):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    newNoise = []\n",
    "    for sample in speech:\n",
    "        len_speech = sample.shape[1]\n",
    "        sample_noise = random.choice(noise)\n",
    "        while sample_noise.shape[1]<len_speech:\n",
    "            sample_noise = torch.concat([sample_noise,sample_noise],dim=1)# Repeat to ensure noise is longer than speech\n",
    "        sample_noise = torch.narrow(sample_noise,1,0,len_speech)# Shorten noise to same length as speech\n",
    "        x = torch.add(sample,sample_noise*ratio1)# Same Ratio 1:1\n",
    "        x2 = torch.add(sample,sample_noise*ratio2)# Same Ratio 1:1\n",
    "        sample_noise = torch.narrow(sample_noise,1,0,len_speech)\n",
    "        X.append(x)\n",
    "        X2.append(x2)\n",
    "        newNoise.append(sample_noise)\n",
    "    return X, X2, newNoise    \n",
    "\n",
    "speech = load_speech()\n",
    "noise = load_noise()\n",
    "# if n_noise>0:\n",
    "#     noise = noise[:n_noise]\n",
    "#print(torch.stack(noise)[0].shape)\n",
    "#noise = noise[5:6]\n",
    "#print(torch.stack(noise)[0].shape)\n",
    "mix1, mix2, noise = add_noise_to_speech(speech, noise, 0.2, 0.5)\n",
    "\n",
    "# STFT\n",
    "N_FFT = 1024\n",
    "N_HOP = 256\n",
    "\n",
    "stft = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=N_HOP,\n",
    "    power=None,\n",
    ")\n",
    "istft = torchaudio.transforms.InverseSpectrogram(n_fft=N_FFT, hop_length=N_HOP)\n",
    "\n",
    "stfts_mix = []\n",
    "for n in range(0,len(mix1)):\n",
    "    x_new = torch.concat([stft(mix1[n]),stft(mix2[n])],dim=0)\n",
    "    stfts_mix.append(x_new)\n",
    "\n",
    "    \n",
    "stfts_clean = []\n",
    "for y in speech:\n",
    "    y_new = stft(y)\n",
    "    y_new = y_new.reshape(513,-1)\n",
    "    stfts_clean.append(y_new)\n",
    "\n",
    "stfts_noise = []\n",
    "i = 0\n",
    "for n in noise:\n",
    "    try:\n",
    "        n_new = stft(n)\n",
    "        stfts_noise.append(n_new.reshape(513,-1))\n",
    "    except Exception: #sometimes noises are very short, e.g. noise[697]\n",
    "        continue\n",
    "def get_irms(stft_clean, stft_noise):\n",
    "    mag_clean = stft_clean.abs() ** 2\n",
    "    mag_noise = stft_noise.abs() ** 2\n",
    "    irm_speech = mag_clean / (mag_clean + mag_noise)\n",
    "    irm_noise = mag_noise / (mag_clean + mag_noise)\n",
    "    return irm_speech[REFERENCE_CHANNEL], irm_noise[REFERENCE_CHANNEL]\n",
    "\n",
    "Y = []\n",
    "for n in range(0,len(noise)):\n",
    "    irm_speech, irm_noise = get_irms(stfts_clean[n].unsqueeze(0), stfts_noise[n].unsqueeze(0))\n",
    "    irm_speech = (irm_speech>THR_S).float()\n",
    "    irm_noise = (irm_noise>THR_N).float()\n",
    "    Y.append(torch.cat((irm_speech.unsqueeze(0),irm_noise.unsqueeze(0)),0))\n",
    "\n",
    "X_h = []\n",
    "stfts_mix_s = torch.stack(stfts_mix)\n",
    "\n",
    "for i in range(0, len(stfts_mix)):\n",
    "    X_i = []\n",
    "    for j in range (0,2):\n",
    "        X_i.append(torch.cat((stfts_mix_s[i][j].real.unsqueeze(0),stfts_mix_s[i][j].imag.unsqueeze(0)),0))\n",
    "    X_h.append(torch.cat((X_i[0],X_i[1]),0))\n",
    "speech_s = torch.stack(speech)\n",
    "noise_s = torch.stack(noise)\n",
    "mix1_s = torch.stack(mix1)\n",
    "Y = torch.stack(Y)\n",
    "X = torch.stack(X_h)\n",
    "if y_mask == False:\n",
    "    Y = speech_s # NEW\n",
    "#return X,Y,speech_s,noise_s,mix1_s,stfts_mix_s\n",
    "X_all = X\n",
    "X_all = X_all.view(2703,513,196,4)\n",
    "speech_all= speech\n",
    "noise_all = noise\n",
    "mix_all = mix1_s\n",
    "stft_all = stfts_mix_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"./outputs/noise_all.wav\",torch.stack(noise_all)[50],16000)\n",
    "torchaudio.save(\"./outputs/noise_all.wav\",speech_s[50],16000)\n",
    "torchaudio.save(\"./outputs/mix_all.wav\",mix1_s[50],16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 3.0518e-05,  ..., 3.4317e-01, 4.1779e-01,\n",
      "         6.4844e-01]])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1898, 0.2145, 0.2414]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(noise_all)[5])\n",
    "print(torch.stack(noise_one)[10])\n",
    "torchaudio.save(\"noise_all.wav\",torch.stack(noise_all)[5],16000)\n",
    "torchaudio.save(\"noise_one.wav\",torch.stack(noise_one)[10],16000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2703, 513, 196, 4])\n"
     ]
    }
   ],
   "source": [
    "# ONE\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "y_mask=True\n",
    "n_noise = -1\n",
    "REFERENCE_CHANNEL = 0\n",
    "SAME_LENGTH = True\n",
    "THR_S = 0.5 # Threshold for speech IRM\n",
    "THR_N = 0.5\n",
    "N_PATH = \"/project/data_asr/CHiME5/data/librenoise/free-sound/\"#\"/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Data/noise/free-sound/\"\n",
    "S_PATH = \"/project/data_asr/CHiME5/data/librenoise/dev/dev-clean/\"\n",
    "def load_noise(N_PATH=N_PATH):\n",
    "    noise = []\n",
    "    for file in  os.listdir(N_PATH):\n",
    "        if file[-4:] == \".wav\":\n",
    "            sound, _ = torchaudio.load(N_PATH+file)\n",
    "            noise.append(sound)\n",
    "    return noise\n",
    "\n",
    "\n",
    "def load_speech(S_PATH=S_PATH):\n",
    "    speech = []\n",
    "    for folder in  os.listdir(S_PATH):\n",
    "        if os.path.isdir(S_PATH+folder):\n",
    "            for subfolder in os.listdir(S_PATH+folder):\n",
    "                if os.path.isdir(S_PATH+folder+\"/\"+subfolder):\n",
    "                    for file in os.listdir(S_PATH+folder+\"/\"+subfolder):\n",
    "                        if file[-5:] == \".flac\":\n",
    "                            sound, _ = torchaudio.load(S_PATH+folder+\"/\"+subfolder+\"/\"+file)\n",
    "                            if SAME_LENGTH:\n",
    "                                try:\n",
    "                                    sound = torch.narrow(sound,1,0,50000)# Narrow to 50000\n",
    "                                except Exception:\n",
    "                                    # add zeros to make sound 50000 long\n",
    "                                    len_sound = sound.shape[1]\n",
    "                                    add_zeros = 50000 - len_sound\n",
    "                                    add_zeros = torch.zeros(add_zeros).reshape(1,-1)\n",
    "                                    sound = torch.concat([sound,add_zeros],dim=1)\n",
    "                            speech.append(sound)\n",
    "    return speech\n",
    "\n",
    "def add_noise_to_speech(speech, noise):\n",
    "    X = []\n",
    "    for sample in speech:\n",
    "        len_speech = sample.shape[1]\n",
    "        sample_noise = torch.concat([noise[6],noise[6],noise[6],noise[6]],dim=1)# Repeat to ensure noise is longer than speech\n",
    "        sample_noise = torch.narrow(sample_noise,1,0,len_speech)# Shorten noise to same length as speech\n",
    "        x = torch.add(sample,sample_noise*0.2)# Same Ratio 1:1\n",
    "        X.append(x)\n",
    "    return X    \n",
    "\n",
    "def add_noise_to_speech2(speech, noise):\n",
    "    X = []\n",
    "    for sample in speech:\n",
    "        len_speech = sample.shape[1]\n",
    "        sample_noise = torch.concat([noise[6],noise[6],noise[6],noise[6]],dim=1)# Repeat to ensure noise is longer than speech\n",
    "        sample_noise = torch.narrow(sample_noise,1,0,len_speech)# Shorten noise to same length as speech\n",
    "        x = torch.add(sample,sample_noise*0.5)# Same Ratio 1:1\n",
    "        X.append(x)\n",
    "    return X \n",
    "\n",
    "def get_one_noise(speech, noise):# Make Noise 6 same length as respective speech\n",
    "    X = []\n",
    "    for sample in speech:\n",
    "        len_speech = sample.shape[1]\n",
    "        sample_noise = torch.concat([noise[6],noise[6],noise[6],noise[6]],dim=1)# Repeat noise to ensure noise is longer than speech\n",
    "        sample_noise = torch.narrow(sample_noise,1,0,len_speech)# Shorten noise to same length as speech\n",
    "        x = sample_noise\n",
    "        X.append(x)\n",
    "    return X\n",
    "\n",
    "# STFT\n",
    "N_FFT = 1024\n",
    "N_HOP = 256\n",
    "\n",
    "stft = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=N_HOP,\n",
    "    power=None,\n",
    ")\n",
    "\n",
    "speech = load_speech()\n",
    "noise = load_noise()\n",
    "X = add_noise_to_speech(speech, noise)\n",
    "X_e = X\n",
    "X2 = add_noise_to_speech2(speech,noise)\n",
    "noise = get_one_noise(speech,noise)\n",
    "stfts_mix = []\n",
    "for n in range(0,len(X)):\n",
    "    x_new = torch.concat([stft(X[n]),stft(X2[n])],dim=0)\n",
    "    stfts_mix.append(x_new)\n",
    "\n",
    "    \n",
    "stfts_clean = []\n",
    "for y in speech:\n",
    "    y_new = stft(y)\n",
    "    y_new = y_new.reshape(513,-1)\n",
    "    stfts_clean.append(y_new)\n",
    "\n",
    "stfts_noise = []\n",
    "for n in noise:\n",
    "    try:\n",
    "        n_new = stft(n)\n",
    "        stfts_noise.append(n_new.reshape(513,-1))\n",
    "    except Exception: #sometimes noises are very short, e.g. noise[697]\n",
    "        continue\n",
    "\n",
    "def get_irms(stft_clean, stft_noise):\n",
    "    mag_clean = stft_clean.abs() ** 2\n",
    "    mag_noise = stft_noise.abs() ** 2\n",
    "    irm_speech = mag_clean / (mag_clean + mag_noise)\n",
    "    irm_noise = mag_noise / (mag_clean + mag_noise)\n",
    "    return irm_speech[REFERENCE_CHANNEL], irm_noise[REFERENCE_CHANNEL]\n",
    "\n",
    "trainY = []\n",
    "for n in range(0,len(noise)):\n",
    "    irm_speech, irm_noise = get_irms(stfts_clean[n].unsqueeze(0), stfts_noise[n].unsqueeze(0))\n",
    "    irm_speech = (irm_speech>THR_S).float()\n",
    "    irm_noise = (irm_noise>THR_N).float()\n",
    "    trainY.append(torch.cat((irm_speech.unsqueeze(0),irm_noise.unsqueeze(0)),0))\n",
    "\n",
    "X = torch.stack(stfts_mix)\n",
    "Y = torch.stack(trainY)\n",
    "\n",
    "# Add second channel to one channel => (513,196,2) -> (513,196,4)\n",
    "def prep_xij(trainX,i,j):\n",
    "    real_part = trainX[i][j].real\n",
    "    imag_part = trainX[i][j].imag\n",
    "    return torch.cat((real_part.unsqueeze(2),imag_part.unsqueeze(2)),2)\n",
    "\n",
    "def prep_x(trainX,i):\n",
    "    x = []\n",
    "    for j in range(0,2):# + Iterate over channels\n",
    "        x.append(prep_xij(trainX,i,j))\n",
    "    x = torch.stack(x,dim=2)\n",
    "    x = x.reshape(513,196,4)\n",
    "    return x\n",
    "\n",
    "X_4 = []\n",
    "for i in range(0,len(X)):\n",
    "    x = X[i]\n",
    "    x = prep_x(X,i)\n",
    "    X_4.append(x)\n",
    "X_4 = torch.stack(X_4)\n",
    "\n",
    "#return X_4,Y,speech,X_e, X\n",
    "print(X_4.shape)\n",
    "X_one = X_4\n",
    "speech_one = speech\n",
    "noise_one = noise\n",
    "mix_one = X_e\n",
    "stft_one = stfts_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2703, 513, 196, 4])\n",
      "torch.Size([2703, 513, 196, 4])\n",
      "tensor([[-0.8135, -0.7360, -0.3900,  0.0422],\n",
      "        [ 0.1335,  0.0230, -0.1164, -0.2497]])\n",
      "tensor([[-0.1300,  0.0000, -0.1298,  0.0000],\n",
      "        [-0.1003,  0.0000, -0.1003,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)\n",
    "print(X_one.shape)\n",
    "print(X_all[0][0][0:2])\n",
    "print(X_one[0][0][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2703, 1, 50000])\n",
      "torch.Size([2703, 1, 50000])\n",
      "tensor([[-3.0518e-05, -3.0518e-05,  0.0000e+00,  ...,  5.6854e-02,\n",
      "          2.7469e-01,  3.2697e-01]])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1898, 0.2145, 0.2414]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(noise_all).shape)\n",
    "print(torch.stack(noise_one).shape)\n",
    "print(noise_all[0])\n",
    "print(noise_one[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"mix1.wav\",mix1[0].reshape(1,-1),16000)\n",
    "torchaudio.save(\"mix2.wav\",mix2[0].reshape(1,-1),16000)\n",
    "torchaudio.save(\"mX.wav\",X[0].reshape(1,-1),16000)\n",
    "torchaudio.save(\"mX2.wav\",X2[0].reshape(1,-1),16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnisse:\n",
    "- Speech ist identisch\n",
    "- NOISE IST ANDERS!!!\n",
    "- X ist unterschiedlich => Y auch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bfclone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e0fe344531d082aecdd86f0ae27c07ef5ff454b4051939cbe7adfbf5a944153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
