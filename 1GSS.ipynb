{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilfedorovsky/miniforge3/envs/ML/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/danilfedorovsky/miniforge3/envs/ML/lib/python3.10/site-packages/torchaudio/_internal/module_utils.py:99: UserWarning: Failed to import soundfile. 'soundfile' backend is not available.\n",
      "  warnings.warn(\"Failed to import soundfile. 'soundfile' backend is not available.\")\n"
     ]
    }
   ],
   "source": [
    "from gss.distribution import CACGMMTrainer\n",
    "import numpy as np\n",
    "from gss.utils import stack_parameters\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:111: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:111: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/wr/spkz8f691xl_gwp76c19_yv40000gn/T/ipykernel_4899/1174320098.py:111: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if value is 1:\n",
      "/var/folders/wr/spkz8f691xl_gwp76c19_yv40000gn/T/ipykernel_4899/1174320098.py:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.bool,\n"
     ]
    }
   ],
   "source": [
    "# Get Guidance from Transcript\n",
    "from gss import mapping\n",
    "from gss.utils import ArrayIntervall\n",
    "\n",
    "def get_activity(\n",
    "        iterator,\n",
    "        *,\n",
    "        perspective,\n",
    "        garbage_class,\n",
    "        dtype=np.bool,\n",
    "        non_sil_alignment_fn=None,\n",
    "        debug=False,\n",
    "        use_ArrayIntervall=False,\n",
    "):\n",
    "\n",
    "    dict_it_S = iterator.groupby(lambda ex: ex['session_id'])\n",
    "\n",
    "    # Dispatcher is a dict with better KeyErrors\n",
    "    all_acitivity = Dispatcher()\n",
    "    for session_id, it_S in dict_it_S.items():\n",
    "\n",
    "        if perspective == 'worn':\n",
    "            perspective_tmp = session_to_speakers[session_id]\n",
    "        elif perspective == 'global_worn':\n",
    "            perspective_tmp = ['P']  # Always from target speaker\n",
    "        elif perspective == 'array':\n",
    "            # The mapping considers missing arrays\n",
    "            perspective_tmp = session_to_arrays[session_id]\n",
    "        else:\n",
    "            perspective_tmp = perspective\n",
    "\n",
    "            if not isinstance(perspective_tmp, (tuple, list)):\n",
    "                perspective_tmp = [perspective_tmp, ]\n",
    "\n",
    "        speaker_ids = mapping.session_to_speakers[session_id]\n",
    "\n",
    "        if use_ArrayIntervall:\n",
    "            assert dtype == np.bool, dtype\n",
    "            zeros = ArrayIntervall\n",
    "\n",
    "            def ones(shape):\n",
    "                arr = zeros(shape=shape)\n",
    "                arr[:] = 1\n",
    "                return arr\n",
    "        else:\n",
    "            import functools\n",
    "            zeros = functools.partial(np.zeros, dtype=dtype)\n",
    "            ones = functools.partial(np.ones, dtype=dtype)\n",
    "\n",
    "        all_acitivity[session_id] = Dispatcher({\n",
    "            p: Dispatcher({\n",
    "                s: zeros(shape=[session_array_to_num_samples[f'{session_id}_{p}']])\n",
    "                # s: ArrayIntervall(shape=[num_samples])\n",
    "                for s in speaker_ids\n",
    "            })\n",
    "            for p in perspective_tmp\n",
    "        })\n",
    "\n",
    "        if garbage_class is True:\n",
    "            for p in perspective_tmp:\n",
    "                num_samples = session_array_to_num_samples[\n",
    "                    f'{session_id}_{p}']\n",
    "                all_acitivity[session_id][p]['Noise'] = ones(\n",
    "                    shape=[num_samples],\n",
    "                )\n",
    "        elif garbage_class is False:\n",
    "            for p in perspective_tmp:\n",
    "                num_samples = session_array_to_num_samples[\n",
    "                    f'{session_id}_{p}']\n",
    "                all_acitivity[session_id][p]['Noise'] = zeros(\n",
    "                    shape=[num_samples]\n",
    "                )\n",
    "        elif garbage_class is None:\n",
    "            pass\n",
    "        elif isinstance(garbage_class, int) and garbage_class > 0:\n",
    "            for noise_idx in range(garbage_class):\n",
    "                for p in perspective_tmp:\n",
    "                    num_samples = session_array_to_num_samples[\n",
    "                        f'{session_id}_{p}'\n",
    "                    ]\n",
    "                    all_acitivity[session_id][p][f'Noise{noise_idx}'] = ones(\n",
    "                        shape=[num_samples]\n",
    "                    )\n",
    "        else:\n",
    "            raise ValueError(garbage_class)\n",
    "\n",
    "        missing_count = 0\n",
    "        for ex in it_S:\n",
    "            for pers in perspective_tmp:\n",
    "                if ex['transcription'] == '[redacted]':\n",
    "                    continue\n",
    "\n",
    "                target_speaker = ex['speaker_id']\n",
    "                # example_id = ex['example_id']\n",
    "\n",
    "                if pers == 'P':\n",
    "                    perspective_mic_array = target_speaker\n",
    "                else:\n",
    "                    perspective_mic_array = pers\n",
    "\n",
    "                if perspective_mic_array.startswith('P'):\n",
    "                    start = ex['start']['worn'][perspective_mic_array]\n",
    "                    end = ex['end']['worn'][perspective_mic_array]\n",
    "                else:\n",
    "                    if not perspective_mic_array in ex['audio_path']['observation']:\n",
    "                        continue\n",
    "                    start = ex['start']['observation'][perspective_mic_array]\n",
    "                    end = ex['end']['observation'][perspective_mic_array]\n",
    "\n",
    "                if non_sil_alignment_fn is None:\n",
    "                    value = 1\n",
    "                else:\n",
    "                    value = non_sil_alignment_fn(ex, perspective_mic_array)\n",
    "                    if value is 1:\n",
    "                        missing_count += 1\n",
    "\n",
    "                if debug:\n",
    "                    all_acitivity[session_id][pers][target_speaker][start:end] += value\n",
    "                else:\n",
    "                    all_acitivity[session_id][pers][target_speaker][start:end] = value\n",
    "        if missing_count > len(it_S) // 2:\n",
    "            raise RuntimeError(\n",
    "                f'Something went wrong.\\n'\n",
    "                f'Expected {len(it_S) * len(perspective_tmp)} times a '\n",
    "                f'finetuned annotation for session {session_id}, but '\n",
    "                f'{missing_count} times they are missing.\\n'\n",
    "                f'Expect that at least {len(it_S) // 2} finetuned annotations '\n",
    "                f'are available, when non_sil_alignment_fn is given.\\n'\n",
    "                f'Otherwise assume something went wrong.'\n",
    "            )\n",
    "\n",
    "        del it_S\n",
    "\n",
    "    return all_acitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from nara_wpe.wpe import wpe\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSS:\n",
    "    iterations: int\n",
    "    iterations_post: int\n",
    "\n",
    "    verbose: bool = True\n",
    "\n",
    "    # use_pinv: bool = False\n",
    "    # stable: bool = True\n",
    "\n",
    "    def __call__(self, Obs, acitivity_freq, debug=False):\n",
    "\n",
    "        initialization = np.asarray(acitivity_freq, dtype=np.float64)\n",
    "        initialization = np.where(initialization == 0, 1e-10, initialization)\n",
    "        initialization = initialization / np.sum(initialization, keepdims=True,\n",
    "                                                axis=0)\n",
    "        initialization = np.repeat(initialization[None, ...], 513, axis=0)\n",
    "\n",
    "        source_active_mask = np.asarray(acitivity_freq, dtype=np.bool)\n",
    "        source_active_mask = np.repeat(source_active_mask[None, ...], 513, axis=0)\n",
    "\n",
    "        cacGMM = CACGMMTrainer()\n",
    "\n",
    "        if debug:\n",
    "            learned = []\n",
    "        all_affiliations = []\n",
    "        F = Obs.shape[-1]\n",
    "        T = Obs.T.shape[-2]\n",
    "        for f in range(F):\n",
    "            if self.verbose:\n",
    "                if f % 50 == 0:\n",
    "                    print(f'{f}/{F}')\n",
    "\n",
    "            # T: Consider end of signal.\n",
    "            # This should not be nessesary, but activity is for inear and not for\n",
    "            # array.\n",
    "            cur = cacGMM.fit(\n",
    "                y=Obs.T[f, ...],\n",
    "                initialization=initialization[f, ..., :T],\n",
    "                iterations=self.iterations,\n",
    "                source_activity_mask=source_active_mask[f, ..., :T],\n",
    "                # return_affiliation=True,\n",
    "            )\n",
    "\n",
    "            if self.iterations_post != 0:\n",
    "                if self.iterations_post != 1:\n",
    "                    cur = cacGMM.fit(\n",
    "                        y=Obs.T[f, ...],\n",
    "                        initialization=cur,\n",
    "                        iterations=self.iterations_post - 1,\n",
    "                    )\n",
    "                affiliation = cur.predict(\n",
    "                    Obs.T[f, ...],\n",
    "                )\n",
    "            else:\n",
    "               affiliation = cur.predict(\n",
    "                   Obs.T[f, ...],\n",
    "                   source_activity_mask=source_active_mask[f, ..., :T]\n",
    "               )\n",
    "\n",
    "            if debug:\n",
    "                learned.append(cur)\n",
    "            all_affiliations.append(affiliation)\n",
    "\n",
    "        posterior = np.array(all_affiliations).transpose(1, 2, 0)\n",
    "\n",
    "        if debug:\n",
    "            learned = stack_parameters(learned)\n",
    "            self.locals = locals()\n",
    "\n",
    "        return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Code/Git Repo/data/1WPE/\"\n",
    "\n",
    "data, sample_rate = torchaudio.load(datapath+\"WPE_S02_P05.wav\")\n",
    "data = data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wr/spkz8f691xl_gwp76c19_yv40000gn/T/ipykernel_38135/4256658286.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  initialization = initialization / np.sum(initialization, keepdims=True,\n",
      "/var/folders/wr/spkz8f691xl_gwp76c19_yv40000gn/T/ipykernel_38135/4256658286.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  source_active_mask = np.asarray(acitivity_freq, dtype=np.bool)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Code/Git Repo/Beamformer/1GSS.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000006?line=0'>1</a>\u001b[0m obs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000006?line=1'>2</a>\u001b[0m gss \u001b[39m=\u001b[39m GSS()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(obs,data)\n",
      "\u001b[1;32m/Users/danilfedorovsky/Documents/10 Collection/00 Studium/00 Letztes Semester/Masterarbeit/Code/Git Repo/Beamformer/1GSS.ipynb Cell 2'\u001b[0m in \u001b[0;36mGSS.__call__\u001b[0;34m(self, Obs, acitivity_freq, debug)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000002?line=23'>24</a>\u001b[0m     learned \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000002?line=24'>25</a>\u001b[0m all_affiliations \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000002?line=25'>26</a>\u001b[0m F \u001b[39m=\u001b[39m Obs\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000002?line=26'>27</a>\u001b[0m T \u001b[39m=\u001b[39m Obs\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danilfedorovsky/Documents/10%20Collection/00%20Studium/00%20Letztes%20Semester/Masterarbeit/Code/Git%20Repo/Beamformer/1GSS.ipynb#ch0000002?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(F):\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "obs = np.array(10)\n",
    "gss = GSS().__call__(obs,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f158735646e3eab0c4059261eebfec0df7fcce3767322491286d467f4f66baf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
