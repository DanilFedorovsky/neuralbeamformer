{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.signal import correlate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/project/data_asr/CHiME5/data/CHiME5/audio/dev/\"\n",
    "\n",
    "# U = mic array with 4 channels, P = Person (2 channels in wav)\n",
    "data_1, sample_rate_1 = torchaudio.load(path+\"S02_U01.CH1.wav\")\n",
    "data_2, sample_rate_2 = torchaudio.load(path+\"S02_U02.CH1.wav\")\n",
    "print(data_1.size(),data_2.size(), sample_rate_1, sample_rate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow data1 and data2\n",
    "data_1 = torch.narrow(data_1, 1, 0, int(data_1.size(dim=1)*0.1)) #1% = 2849292\n",
    "data_2 = torch.narrow(data_2, 1, 0, int(data_2.size(dim=1)*0.1))\n",
    "inputs = [data_1,data_2]\n",
    "print(data_1.size(dim=1))\n",
    "print(inputs[0].size(), inputs[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask estimation with CGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libs.beamformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/dev/shm/danil/Beamformer/2MVDR_BF.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.59/dev/shm/danil/Beamformer/2MVDR_BF.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbeamformer\u001b[39;00m \u001b[39mimport\u001b[39;00m MvdrBeamformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libs.beamformer'"
     ]
    }
   ],
   "source": [
    "from libs.beamformer import MvdrBeamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "LOG_PI = math.log(math.pi)\n",
    "\n",
    "def gmm_posterior(obs, phi, sigma_inv, sigma_det):\n",
    "    \"\"\"\n",
    "        This function returns log-posterior on GMM model G(x; 0, \\phi * \\sigma) given x\n",
    "        for efficiency, do not calculate matrix invert and determinant inner function\n",
    "        log G(x; \\mu, \\sigma) = -0.5 * D * log\\pi - 0.5 * log |\\sigma| - 0.5 * \\\n",
    "                (x - \\mu) * \\sigma^{-1} * (x - \\mu)^T\n",
    "        return complex type\n",
    "    \"\"\"\n",
    "    dim = obs.size\n",
    "    # transfer obs[vector] to matrix\n",
    "    obs = np.matrix(obs)\n",
    "    # exponent part, \\mu = 0\n",
    "    comp_e = obs * sigma_inv * obs.T / phi\n",
    "    assert comp_e.size == 1\n",
    "    # post = np.complex(-0.5 * (LOG_PI * dim + np.log(np.linalg.det(sigma)) + comp_e))\n",
    "    post = np.complex(-0.5 * (LOG_PI * dim + np.log(sigma_det * (phi ** dim)) + comp_e))\n",
    "    return post\n",
    "\n",
    "def gmm_posterior_slow(obs, sigma):\n",
    "    dim = obs.size\n",
    "    obs = np.matrix(obs)\n",
    "    comp_e = obs * sigma.I * obs.T\n",
    "    post = np.complex(-0.5 * (LOG_PI * dim + np.log(np.linalg.det(sigma)) + comp_e))\n",
    "    return post\n",
    "\n",
    "\n",
    "class CGMM(object):\n",
    "    def __init__(self, num_bins, time_steps, num_channels):\n",
    "        \"\"\"\n",
    "            num_bins:   number of bins along frequent axis(usually 257)\n",
    "            time_steps: number of frames per channel\n",
    "            num_channels: number of channels, equals GMM dim\n",
    "        \"\"\"\n",
    "        self.num_bins, self.time_steps = num_bins, time_steps\n",
    "        self.dim = num_channels\n",
    "        # lambda, phi, R for noisy/noise part\n",
    "        self.lambda_ = np.zeros([num_bins, time_steps]).astype(np.complex)\n",
    "        self.phi     = np.ones([num_bins, time_steps]).astype(np.complex)\n",
    "        self.posterior = np.zeros([self.num_bins, self.time_steps]).astype(np.complex)\n",
    "\n",
    "    def init_sigma(self, sigma):\n",
    "        \"\"\"\n",
    "            Inputs: sigma is a np.matrix list \n",
    "            Keeps \\sigma^{-1} and det(\\sigma), \\sigma equals \\mean(y^H * y)\n",
    "        \"\"\"\n",
    "        assert type(sigma) == list\n",
    "        self.sigma_inv = [mat.I for mat in sigma]\n",
    "        self.sigma_det = [np.linalg.det(mat) for mat in sigma]\n",
    "        \n",
    "    def covar_entropy(self):\n",
    "        \"\"\"\n",
    "            Return entropy among eigenvalues of correlation matrix on \n",
    "            each frequency bin.\n",
    "        \"\"\"\n",
    "        entropy = []\n",
    "        for sigma_inv in self.sigma_inv:\n",
    "            egval, _ = np.linalg.eig(sigma_inv.I)\n",
    "            real_eigen = egval.real / egval.real.sum()\n",
    "            entropy.append(-(real_eigen * np.log(real_eigen)).sum())\n",
    "        return entropy\n",
    "\n",
    "    def check_inputs(self, inputs):\n",
    "        num_bins, time_steps, num_channels = inputs.shape\n",
    "        assert num_bins == self.num_bins and time_steps == self.time_steps \\\n",
    "            and num_channels == self.dim, 'Inputs dim does not match CGMM config'\n",
    "\n",
    "    # def log_likelihood(self, spectrums):\n",
    "    #     self.check_inputs(spectrums)\n",
    "    #     posteriors = 0.0\n",
    "    #     for f in range(self.num_bins):\n",
    "    #         for t in range(self.time_steps):\n",
    "    #             posteriors += self.lambda_[f, t] * gmm_posterior(spectrums[f, t], \\\n",
    "    #                     self.phi[f, t], self.sigma_inv[f], self.sigma_det[f]) \n",
    "    #     return posteriors\n",
    "\n",
    "    def accu_stats(self, spectrums):\n",
    "        \"\"\"\n",
    "            Return posteriors on each frequency bin(size: F x T), in order to use\n",
    "            them when updating lambda, we keep it as a class member\n",
    "            We can get log_likelihood(function Q: eq.9) from posterior(by sum and average)\n",
    "        \"\"\"\n",
    "        self.check_inputs(spectrums)\n",
    "        # stats = np.zeros([self.num_bins, self.time_steps]).astype(np.complex)\n",
    "        for f in range(self.num_bins):\n",
    "            for t in range(self.time_steps):\n",
    "                self.posterior[f, t] = gmm_posterior(spectrums[f, t], self.phi[f, t], \\\n",
    "                        self.sigma_inv[f], self.sigma_det[f]) \n",
    "        log_likelihood = (self.lambda_ * self.posterior).sum() / (self.num_bins * self.time_steps)\n",
    "        return self.posterior, log_likelihood\n",
    "\n",
    "    def update_lambda(self, spectrums, stats):\n",
    "        \"\"\"\n",
    "            stats: sum of stats returned by function accu_stats\n",
    "            update lambda: lambda = stats / \\sum(stats) ref. eq.10\n",
    "            Here using self.posterior calculated in function accu_stats to accelerate\n",
    "            training progress.\n",
    "        \"\"\"\n",
    "        print('update lambda...')\n",
    "        assert stats.shape == self.posterior.shape\n",
    "        # delete: avoid duplicated computation\n",
    "        # for f in range(self.num_bins):\n",
    "        #     for t in range(self.time_steps):\n",
    "        #         self.lambda_[f, t] = gmm_posterior(spectrums[f, t], self.phi[f, t], \\\n",
    "        #                 self.sigma_inv[f], self.sigma_det[f])\n",
    "        self.lambda_ = self.posterior / stats\n",
    "\n",
    "    def update_phi(self, covar):\n",
    "        \"\"\"\n",
    "            Update phi: ref. eq.9\n",
    "        \"\"\"\n",
    "        print('update phi...')\n",
    "        for f in range(self.num_bins):\n",
    "            for t in range(self.time_steps):\n",
    "                self.phi[f, t] = np.trace(covar[f * self.time_steps + t] * self.sigma_inv[f])\n",
    "        self.phi = self.phi / self.dim\n",
    "\n",
    "    def update_sigma(self, covar):\n",
    "        \"\"\"\n",
    "            Update R: ref. eq.12\n",
    "        \"\"\"\n",
    "        print('update sigma...')\n",
    "        for f in range(self.num_bins):\n",
    "            sum_lambda = self.lambda_[f].sum()\n",
    "            R = np.matrix(np.zeros([self.dim, self.dim]).astype(np.complex))\n",
    "            for t in range(self.time_steps):\n",
    "                R += self.lambda_[f, t] * covar[f * self.time_steps + t] / self.phi[f, t]\n",
    "            R = R / sum_lambda\n",
    "            self.sigma_inv[f] = R.I \n",
    "            self.sigma_det[f] = np.linalg.det(R)\n",
    "\n",
    "    def update_parameters(self, spectrums, covar, stats):\n",
    "        \"\"\"\n",
    "            spectrums:  multi-channel training data(size: F x T x M)\n",
    "            covar:      a python list, each item is a precomputed correlation matrix(y * y^H, \n",
    "                        type: np.matrix), we did it to avoid duplicate computing\n",
    "            stats:      sum of stats in each CGMM part\n",
    "        \"\"\"\n",
    "        self.check_inputs(spectrums)\n",
    "        assert len(covar) == self.num_bins * self.time_steps and type(covar) == list\n",
    "        self.update_lambda(spectrums, stats)\n",
    "        self.update_phi(covar)\n",
    "        self.update_sigma(covar)\n",
    "\n",
    "class CGMMTrainer(object):\n",
    "    def __init__(self, num_bins, time_steps, num_channels):\n",
    "        self.noise_part = CGMM(num_bins, time_steps, num_channels)\n",
    "        self.noisy_part = CGMM(num_bins, time_steps, num_channels)\n",
    "        self.num_bins   = num_bins\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def init_sigma(self, spectrums):\n",
    "        \"\"\"\n",
    "            covar: precomputed correlation matrix of each channel\n",
    "            Here we init noisy_part'R as correlation matrix of observed signal\n",
    "        \"\"\"\n",
    "        print(\"initialize sigma...\")\n",
    "        num_bins, time_steps, num_channels = spectrums.shape\n",
    "        self.covar = [y.H * y for y in [np.matrix(spectrums[f, t]) \\\n",
    "                for f in range(num_bins) for t in range(time_steps)]]\n",
    "        self.noise_part.init_sigma([np.matrix(np.eye(num_channels, \\\n",
    "                num_channels).astype(np.complex)) for f in range(num_bins)])\n",
    "        self.noisy_part.init_sigma([sum(self.covar[f * time_steps: \\\n",
    "              (f + 1) * time_steps]) / time_steps for f in range(num_bins)])\n",
    "        \n",
    "    # def log_likelihood(self, spectrums):\n",
    "    #     return (self.noise_part.log_likelihood(spectrums) + \\\n",
    "    #             self.noisy_part.log_likelihood(spectrums)) / (self.num_bins * self.time_steps)\n",
    "\n",
    "    def accu_stats(self, spectrums):\n",
    "        print('accumulate statstics...')\n",
    "        stats_y, post_y = self.noisy_part.accu_stats(spectrums)\n",
    "        stats_n, post_n = self.noise_part.accu_stats(spectrums)\n",
    "        return stats_y + stats_n, post_y + post_n\n",
    "    \n",
    "    def update_parameters(self, spectrums, stats):\n",
    "        self.noise_part.update_parameters(spectrums, self.covar, stats)\n",
    "        self.noisy_part.update_parameters(spectrums, self.covar, stats)\n",
    "\n",
    "    def noise_lambda(self):\n",
    "        e_n = self.noise_part.covar_entropy()\n",
    "        e_y = self.noisy_part.covar_entropy()\n",
    "        lambda_ = []\n",
    "        for f in range(self.num_bins):\n",
    "           lambda_.append(self.noise_part.lambda_[f] if e_n[f] > e_y[f] else self.noisy_part.lambda_[f])\n",
    "        return np.array(lambda_)\n",
    "\n",
    "    def save_param(self, dest):\n",
    "        noise_lambda = self.noise_lambda()\n",
    "        if not os.path.exists(dest):\n",
    "            os.mkdir(dest)\n",
    "        np.save(os.path.join(dest, 'noise_lambda'), noise_lambda)\n",
    "        \n",
    "    def train(self, spectrums, iters=30):\n",
    "        self.init_sigma(spectrums)\n",
    "        stats, likelihood = self.accu_stats(spectrums)\n",
    "        for it in range(1, iters + 1):\n",
    "            self.update_parameters(spectrums, stats)\n",
    "            stats, likelihood = self.accu_stats(spectrums)\n",
    "            print('epoch {0:2d}: Likelihood = ({1.real:.5f}, {1.imag:.5f}i)'.format(it, likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from utils import MultiChannelWrapper\n",
    "from cgmm import CGMMTrainer\n",
    "\n",
    "def train(args):\n",
    "    wrapper = MultiChannelWrapper(args.descriptor)  \n",
    "    (time_steps, num_bins), spectrums = wrapper.spectrums()\n",
    "    trainer = CGMMTrainer(num_bins, time_steps, len(spectrums))\n",
    "    start_time = time.time()\n",
    "    trainer.train(np.transpose(spectrums), iters=args.iters)\n",
    "    finish_time = time.time()\n",
    "    print('Total raining time: {:.3f}s'.format(finish_time - start_time))\n",
    "    trainer.save_param(args.save_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Training CGMM on multiple channel\")\n",
    "    parser.add_argument('descriptor', type=str,\n",
    "                        help=\"\"\"descriptor of multiple channel location\"\"\")\n",
    "    parser.add_argument('-i', '--iters',\n",
    "                        dest='iters', type=int, default='10',\n",
    "                        help=\"\"\"number of iterations to train\"\"\")\n",
    "    parser.add_argument('-s', '--save',\n",
    "                        dest='save_dir', type=str, default='.',\n",
    "                        help=\"\"\"directory to save sigma of CGMM\"\"\")\n",
    "    args = parser.parse_args()\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVDR Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_d(speech):\n",
    "    \"\"\"use the principal component of the estimated power spectral\n",
    "    density matrix of speech: d = P {Î¦XX}.\"\"\"\n",
    "    phi_speech = np.matrix(speech)\n",
    "    pca = PCA(n_components=1)\n",
    "    principal_component = pca.fit_transform(phi_speech)\n",
    "    return principal_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvdr_beamformer(d, noise, spectrum):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    - steering vector d (Nx1)\n",
    "    - sigma noise (NxN)\n",
    "    - spectrum (in this bin, TXN)\n",
    "    \"\"\"\n",
    "    d = np.matrix(d).T # 1xN => Nx1\n",
    "    spectrum = np.matrix(spectrum).T # TxN => NxT\n",
    "    phiNN_inv = np.matrix(noise).I\n",
    "\n",
    "    w = phiNN_inv * d / (d.H * phiNN_inv * d)\n",
    "    result_spectrum = w.H * spectrum\n",
    "    return result_spectrum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f0c822f1f3471cfda557225f32a3325398c976884d8d093b8fd824f1bbe21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
